---
title: "Building Agentic Workflows in R with axolotr"
author: "Matthew Hirschey"
date: "2025-08-09"
format:
  revealjs:
    theme: [default, custom.scss]
    slide-number: true
    footer: "UseR! 2025"
    logo: "https://raw.githubusercontent.com/heurekalabsco/axolotr/main/man/figures/logo.png"
    highlight-style: github
    width: 1050
    height: 700
    margin: 0.1
    mermaid: 
      theme: default
execute:
  echo: true
  warning: false
  message: false
knitr:
  opts_chunk:
    mermaid.echo: false
---

## LLMs Are Everywhere

::: columns
::: {.column width="60%"}
### The AI Revolution in Coding

- ChatGPT, Claude, Copilot...
- Natural language â†’ Working code
- Debug errors in seconds
- Generate entire functions
- Explain complex algorithms

::: {.fragment}
**But how do we integrate them into R workflows?**
:::
:::

::: {.column width="40%"}
### Common Use Cases

- ğŸ“Š Data analysis
- ğŸ› Debugging
- ğŸ“ Documentation
- ğŸ”„ Refactoring
- ğŸ§ª Test writing
- ğŸ“ˆ Visualization
:::
:::

## Understanding AI Agents

::: {.hide-source}
```{mermaid}
%%{init: {'theme':'default'}}%%
flowchart LR
    A[Agent] --> B[Think]
    B --> C[Act]
    C --> D[Observe]
    D --> B
    
    style A fill:#1a237e,color:#fff
    style B fill:#e3f2fd
    style C fill:#e3f2fd
    style D fill:#e3f2fd
```
:::

### The Think-Act-Observe Loop

::: {.incremental}
- **Think**: Analyze the situation and plan next steps
- **Act**: Execute actions using available tools
- **Observe**: Evaluate results and adapt
- **Repeat**: Continue until goal is achieved
:::

::: {.fragment}
**Agents are autonomous, but that's not always what we need...**
:::

## Workflow Evolution {.smaller}

| Feature | Traditional Workflow | Agentic Workflow | Full Agent |
|---------|---------------------|------------------|------------|
| **LLM Integration** | âŒ None | âœ… Yes | âœ… Yes |
| **Autonomy** | âŒ None | âœ… Task-specific | âœ… Full |
| **Goal Setting** | âŒ Human-defined | âŒ Human-defined | âœ… Self-directed |
| **Memory** | âŒ None | âŒ None | âœ… Persistent |
| **Error Handling** | âŒ Manual | âœ… Self-correcting | âœ… Self-correcting |
| **Tool Usage** | âŒ Predefined | âœ… Dynamic | âœ… Dynamic |
| **Complexity** | ğŸŸ¢ Low | ğŸŸ¡ Medium | ğŸ”´ High |
| **Control** | ğŸŸ¢ Full | ğŸŸ¢ High | ğŸ”´ Limited |


## ğŸ¯ Agentic Workflows

::: columns
::: {.column width="50%"}
- Practical balance of automation and control
- Perfect for data analysis tasks
- Easy to implement and debug
:::

::: {.column width="50%"}
![](images/platypus.jpg)
:::
:::


## The Challenge: LLMs in R {.smaller}

::: columns
::: {.column width="50%"}
**Multiple APIs**

- OpenAI
- Anthropic  
- Google
- Groq
- ...and more
:::

::: {.column width="50%"}
**Different Requirements**

- Authentication methods
- Request formats
- Response structures
- Error handling
- Rate limits
:::
:::

::: {.fragment}
### We need a unified approach! ğŸ¯
:::

## Introducing axolotr

```{r}
#| echo: false
#| message: false
#| warning: false
suppressPackageStartupMessages({
  library(axolotr)
  library(tidyverse)
})
```

::: panel-tabset
### Simple Interface

```{r}
#| eval: false
# One function to rule them all
response <- ask("What is the capital of France?")

# Choose your model
response <- ask("Explain R factors", model = "claude")
response <- ask("Explain R factors", model = "gpt-4o")
response <- ask("Explain R factors", model = "gemini")
```

### Model Flexibility

```{r}
#| eval: false
# Generic providers
ask("Your prompt", model = "anthropic")  # Claude 3.7 Sonnet
ask("Your prompt", model = "openai")     # GPT-4o
ask("Your prompt", model = "google")     # Gemini 1.5 Pro

# Specific versions
ask("Your prompt", model = "claude-3-7-sonnet-latest")
ask("Your prompt", model = "gpt-4o")
ask("Your prompt", model = "llama3-70b-8192")
```
:::

## Problem: Manual EDA is Repetitive

Every analysis starts the same way:

```{r}
#| eval: false
data <- read_csv("data.csv")
glimpse(data)
summary(data)
# Plot distributions...
# Check correlations...
# Look for missing values...
# Create visualizations...
```

::: {.fragment}
### What if an LLM could do this for us? ğŸ¤”
:::

## Solution Architecture

::: {.hide-source}
```{mermaid}
%%{init: {'theme':'default'}}%%
flowchart LR
    A[Dataset] --> B[Auto-EDA<br/>Function]
    B --> C[Generate<br/>Plan]
    C --> D[For Each<br/>Task]
    D --> E[Generate<br/>Code]
    E --> F[Review<br/>Code]
    F --> G{OK?}
    G -->|No| E
    G -->|Yes| H[Execute]
    H --> I{Success?}
    I -->|No| J[Error<br/>Feedback]
    J --> E
    I -->|Yes| K[Next<br/>Task]
    K --> D
```
:::

## Key Implementation: Error-Correcting Loop

```{r}
#| eval: false
#| code-line-numbers: "2-4|6-7|9-11|14-19"
for (attempt in 1:max_attempts) {
  # Generate code with context about previous errors
  code <- generate_analysis_code(task, data_name, error_msg, 
                                model = generation_model)
  
  # Review generated code before execution
  review <- review_code(code, task, model = review_model)
  
  if (!grepl("APPROVED", review)) {
    error_msg <- review
    next  # Try again
  }
  
  # Execute safely
  result <- safe_eval(code)
  
  if (result$success) {
    break  # Success!
  } else {
    error_msg <- result$error  # Feed back for next attempt
  }
}
```

## Live Demo: Auto-EDA in Action

```{r}
#| eval: false
# Load our auto-EDA tool
source("auto_eda.R")

# Run on built-in dataset
auto_eda(mtcars, 
         generation_model = "claude",
         review_model = "gpt-4o")
```

::: {.fragment}
### Watch for:
- Plan generation
- Code creation & review
- Error correction
- Multi-model collaboration
- **NEW**: All outputs saved to `auto_eda_output/` ğŸ“
:::

## Multi-Model Usage Example

```{r}
#| eval: false
#| code-line-numbers: "1-3|5-8|10-13"
# Use Claude for creative tasks
plan <- ask("Create an analysis plan for this dataset", 
           model = "claude")

# Use GPT-4 for code review
review <- ask(
  paste("Review this R code:", code, "Is it safe to run?"),
  model = "gpt-4o"
)

# Use Groq for fast iterations
quick_fix <- ask(
  paste("Fix this error:", error_msg),
  model = "llama3-70b-8192"  # Via Groq
)
```

## axolotr vs ellmer

| Feature | axolotr | ellmer |
|---------|---------|---------|
| **Design** | Functional | Object-Oriented (R6) |
| **Interface** | `ask()` | `chat$chat()` |
| **State** | Stateless | Stateful conversations |
| **Integration** | Standalone | Tidyverse ecosystem |
| **Learning Curve** | Minimal | Moderate |

::: {.fragment}
### Choose based on your needs! Both are excellent tools ğŸ› ï¸
:::

## Takeaways

::: {.incremental}
1. **Agentic workflows** make LLMs practical for everyday R tasks

2. **axolotr** provides dead-simple multi-provider access

3. **Error handling** is key - LLMs make mistakes!

4. **Multi-model** approaches leverage each model's strengths

5. **Start simple** - even basic automation saves time
:::

## Resources & Next Steps

### ğŸ“¦ Get Started
```{r}
#| eval: false
devtools::install_github("heurekalabsco/axolotr")
```

### ğŸ“š Learn More
- GitHub: [github.com/heurekalabsco/axolotr](https://github.com/heurekalabsco/axolotr)
- This talk: [github.com/matthewhirschey/useR_talk_axolotr](https://github.com/matthewhirschey/useR_talk_axolotr)

### ğŸ’¡ Ideas to Try
- Automated report generation
- Code documentation
- Data validation workflows
- Test generation

## Thank You! Questions? {.center}

::: columns
::: {.column width="50%"}
![](https://raw.githubusercontent.com/heurekalabsco/axolotr/main/man/figures/logo.png){width=300}
:::

::: {.column width="50%"}
### Matthew Hirschey
- Associate Professor, Duke University
- Director, Center for Computational Thinking

### Contact
- GitHub: @matthewhirschey
- Email: matthew.hirschey@duke.edu
:::
:::
